{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MedGemma 1.5 AutoRound 4-bit + RadGraph F1 è¯„ä¼°\n",
        "\n",
        "**æ¨¡å‹**: [Ashley101179/medgemma-1.5-4b-it-4bit-autoround](https://huggingface.co/Ashley101179/medgemma-1.5-4b-it-4bit-autoround)\n",
        "\n",
        "- **é‡åŒ–æ–¹æ³•**: Intel AutoRound (GPTQ format)\n",
        "- **ä½æ•°**: 4-bit\n",
        "- **æ˜¾å­˜**: ~4GB (åŸæ¨¡å‹ ~10GB)\n",
        "- **è¯„ä¼°**: RadGraph F1 on MIMIC-CXR\n",
        "\n",
        "## ç¯å¢ƒè¯´æ˜\n",
        "- **Python**: 3.12ï¼ˆKaggle é»˜è®¤ï¼Œæ— éœ€é™çº§ï¼‰\n",
        "- **GPU**: Kaggle P100\n",
        "- **ä¾èµ–**: transformers 4.47.1 + auto-gptq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 1: å®‰è£…ä¾èµ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kaggle P100: transformers 4.47.1 + auto-gptq\n",
        "import subprocess, sys, os, shutil\n",
        "\n",
        "TF_ENV = \"/kaggle/working/tf_env\"\n",
        "CONSTRAINTS = \"/kaggle/working/constraints.txt\"\n",
        "\n",
        "# æ¸…ç†æ—§ç¯å¢ƒ\n",
        "if os.path.exists(TF_ENV):\n",
        "    shutil.rmtree(TF_ENV)\n",
        "\n",
        "# 1. ä½¿ç”¨ Kaggle é¢„è£… PyTorchï¼ˆé€šå¸¸æ˜¯ 2.x + cu121ï¼Œå…¼å®¹ P100ï¼‰\n",
        "print(\"ä½¿ç”¨ Kaggle é¢„è£…çš„ PyTorch...\")\n",
        "\n",
        "# 2. åˆ›å»ºçº¦æŸæ–‡ä»¶ï¼ˆå¼ºåˆ¶é”å®š transformers ç‰ˆæœ¬ï¼‰\n",
        "with open(CONSTRAINTS, \"w\") as f:\n",
        "    f.write(\"transformers==4.47.1\\n\")\n",
        "\n",
        "# 3. å®‰è£… transformers åˆ° TF_ENVï¼ˆä½¿ç”¨æ¸…åé•œåƒï¼‰\n",
        "subprocess.run([\n",
        "    \"pip\", \"install\", \"--target\", TF_ENV, \"-q\", \"-c\", CONSTRAINTS,\n",
        "    \"transformers==4.47.1\", \"pillow<12\", \"jinja2\",\n",
        "    \"-i\", \"https://pypi.tuna.tsinghua.edu.cn/simple\"\n",
        "], check=True)\n",
        "\n",
        "# 4. å®‰è£… auto-gptqï¼ˆGPTQ åç«¯ï¼Œä½¿ç”¨æ¸…åé•œåƒï¼‰\n",
        "print(\"å®‰è£… auto-gptq...\")\n",
        "subprocess.run([\n",
        "    \"pip\", \"install\", \"-q\", \"auto-gptq\", \"optimum\", \"accelerate\",\n",
        "    \"-i\", \"https://pypi.tuna.tsinghua.edu.cn/simple\"\n",
        "], check=True)\n",
        "\n",
        "# 5. å®‰è£… radgraph åˆ°ç³»ç»Ÿï¼ˆä½¿ç”¨æ¸…åé•œåƒï¼‰\n",
        "subprocess.run([\n",
        "    \"pip\", \"install\", \"-q\", \"radgraph\",\n",
        "    \"-i\", \"https://pypi.tuna.tsinghua.edu.cn/simple\"\n",
        "], check=True)\n",
        "\n",
        "# 6. è®¾ç½®è·¯å¾„ä¼˜å…ˆçº§\n",
        "sys.path.insert(0, TF_ENV)\n",
        "\n",
        "print(\"âœ… å®‰è£…å®Œæˆï¼Œè¯·ç«‹åˆ» Restart Sessionï¼Œç„¶å Run All\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 2: HuggingFace ç™»å½•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "from huggingface_hub import login\n",
        "\n",
        "try:\n",
        "    tok = UserSecretsClient().get_secret(\"zhuxirui11\")\n",
        "    if tok:\n",
        "        login(token=tok)\n",
        "        print(\"âœ… HF ç™»å½•æˆåŠŸ\")\n",
        "    else:\n",
        "        print(\"âš ï¸ Token ä¸ºç©º\")\n",
        "except Exception as e:\n",
        "    print(\"âŒ æœªé…ç½® zhuxirui11 Secret\")\n",
        "    print(\"\\nè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®ï¼š\")\n",
        "    print(\"1. ç‚¹å‡»å³ä¾§ 'Add-ons' â†’ 'Secrets'\")\n",
        "    print(\"2. Label å¡«å†™ï¼šzhuxirui11\")\n",
        "    print(\"3. Value å¡«å†™ä½ çš„ HF tokenï¼ˆä» https://huggingface.co/settings/tokens è·å–ï¼‰\")\n",
        "    print(\"4. ä¿å­˜åé‡æ–°è¿è¡Œæœ¬ Cell\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 3: ç¯å¢ƒæ£€æŸ¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, torch\n",
        "\n",
        "print(f\"Python: {sys.version}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    USE_BF16 = torch.cuda.get_device_capability(0)[0] >= 8\n",
        "    DTYPE = torch.bfloat16 if USE_BF16 else torch.float16\n",
        "    print(f\"Precision: {'BF16' if USE_BF16 else 'FP16 (P100)'}\")\n",
        "else:\n",
        "    DTYPE = torch.float32\n",
        "    print(\"âš ï¸ No GPU, using FP32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 4: è·¯å¾„é…ç½®ä¸ç‰ˆæœ¬æ£€æŸ¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os, gc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ç¡®ä¿ TF_ENV ä¼˜å…ˆ\n",
        "TF_ENV = \"/kaggle/working/tf_env\"\n",
        "if TF_ENV not in sys.path:\n",
        "    sys.path.insert(0, TF_ENV)\n",
        "elif sys.path[0] != TF_ENV:\n",
        "    sys.path.remove(TF_ENV)\n",
        "    sys.path.insert(0, TF_ENV)\n",
        "\n",
        "# Kaggle æ•°æ®é›†è·¯å¾„\n",
        "DATASET_ROOT = \"/kaggle/input/datasets/simhadrisadaram/mimic-cxr-dataset/official_data_iccv_final\"\n",
        "CSV_CANDIDATES = [\n",
        "    \"/kaggle/input/datasets/xiruizhu1111/clean-data/mimic_eval_single_image_final_233.csv\",\n",
        "    \"/kaggle/input/datasets/xiruizhu1111/clean-train-data/mimic_eval_single_image_final_233.csv\",\n",
        "    \"/kaggle/input/clean-data/mimic_eval_single_image_final_233.csv\",\n",
        "    \"/kaggle/working/mimic_eval_single_image_final_233.csv\",\n",
        "]\n",
        "\n",
        "# æŸ¥æ‰¾ CSV æ–‡ä»¶\n",
        "CSV_PATH = None\n",
        "for p in CSV_CANDIDATES:\n",
        "    if os.path.exists(p):\n",
        "        CSV_PATH = p\n",
        "        break\n",
        "\n",
        "if not CSV_PATH:\n",
        "    print(\"âŒ æœªæ‰¾åˆ° CSV æ–‡ä»¶ï¼\")\n",
        "    print(\"å°è¯•çš„è·¯å¾„ï¼š\")\n",
        "    for p in CSV_CANDIDATES:\n",
        "        print(f\"  - {p}\")\n",
        "    print(\"\\nè¯·æ£€æŸ¥ï¼š\")\n",
        "    print(\"1. æ˜¯å¦å·²æ·»åŠ åŒ…å« CSV çš„æ•°æ®é›†ï¼Ÿï¼ˆå³ä¾§ Add Dataï¼‰\")\n",
        "    print(\"2. CSV æ–‡ä»¶åæ˜¯å¦ä¸º 'mimic_eval_single_image_final_233.csv'ï¼Ÿ\")\n",
        "    raise FileNotFoundError(\"CSV æ–‡ä»¶ä¸å­˜åœ¨\")\n",
        "\n",
        "# éªŒè¯ transformers ç‰ˆæœ¬\n",
        "import transformers\n",
        "tf_ver = transformers.__version__\n",
        "if tf_ver.startswith('5.'):\n",
        "    raise RuntimeError(\n",
        "        f\"âŒ transformers {tf_ver} ä¸å…¼å®¹ï¼éœ€è¦ 4.47.1\\n\"\n",
        "        f\"è§£å†³æ–¹æ³•ï¼šé‡æ–°è¿è¡Œ Cell 1ï¼Œç¡®ä¿çœ‹åˆ° 'transformers-4.47.1'ï¼Œç„¶å Restart Session\"\n",
        "    )\n",
        "print(f\"âœ… transformers: {tf_ver}\")\n",
        "\n",
        "print(f\"Dataset: {DATASET_ROOT}\")\n",
        "print(f\"âœ… CSV: {CSV_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 4.5: CSV æ£€æŸ¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ£€æŸ¥ CSV æ–‡ä»¶ç»“æ„\n",
        "import pandas as pd\n",
        "\n",
        "df_check = pd.read_csv(CSV_PATH)\n",
        "\n",
        "print(f\"âœ… CSV æ–‡ä»¶åŠ è½½æˆåŠŸï¼\")\n",
        "print(f\"æ€»è¡Œæ•°: {len(df_check)}\")\n",
        "print(f\"\\nåˆ—å: {list(df_check.columns)}\")\n",
        "print(f\"\\nå‰ 3 è¡Œæ•°æ®é¢„è§ˆï¼š\")\n",
        "print(df_check.head(3))\n",
        "\n",
        "# æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨\n",
        "print(\"\\n=== å…³é”®åˆ—æ£€æŸ¥ ===\")\n",
        "has_img_path = \"Image_Path\" in df_check.columns\n",
        "has_ground_truth = \"Ground_Truth\" in df_check.columns or \"text\" in df_check.columns\n",
        "has_subject_id = \"subject_id\" in df_check.columns\n",
        "has_view = \"View\" in df_check.columns\n",
        "\n",
        "print(f\"Image_Path åˆ—: {'âœ… å­˜åœ¨' if has_img_path else 'âŒ ä¸å­˜åœ¨ï¼ˆå°†æŸ¥æ‰¾ PA/AP/Lateral åˆ—ï¼‰'}\")\n",
        "print(f\"Ground_Truth/text åˆ—: {'âœ… å­˜åœ¨' if has_ground_truth else 'âŒ ä¸å­˜åœ¨'}\")\n",
        "print(f\"subject_id åˆ—: {'âœ… å­˜åœ¨' if has_subject_id else 'âš ï¸ ä¸å­˜åœ¨'}\")\n",
        "print(f\"View åˆ—: {'âœ… å­˜åœ¨' if has_view else 'âš ï¸ ä¸å­˜åœ¨ï¼ˆå°†é»˜è®¤ä½¿ç”¨ PAï¼‰'}\")\n",
        "\n",
        "if not has_img_path:\n",
        "    view_cols = [c for c in ['PA', 'AP', 'Lateral'] if c in df_check.columns]\n",
        "    if view_cols:\n",
        "        print(f\"\\næ‰¾åˆ°è§†å›¾åˆ—: {view_cols}\")\n",
        "        print(f\"ç¤ºä¾‹è·¯å¾„: {df_check[view_cols[0]].iloc[0]}\")\n",
        "    else:\n",
        "        print(\"\\nâŒ è­¦å‘Šï¼šæœªæ‰¾åˆ°å›¾ç‰‡è·¯å¾„åˆ—ï¼ˆImage_Path æˆ– PA/AP/Lateralï¼‰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 5: åŠ è½½ AutoRound 4-bit é‡åŒ–æ¨¡å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ¸…é™¤ transformers ç¼“å­˜\n",
        "for k in list(sys.modules.keys()):\n",
        "    if k == \"transformers\" or k.startswith(\"transformers.\"):\n",
        "        del sys.modules[k]\n",
        "\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
        "\n",
        "model_id = \"Ashley101179/medgemma-1.5-4b-it-4bit-autoround\"\n",
        "print(f\"Loading AutoRound 4-bit model ({DTYPE})...\")\n",
        "print(\"âš ï¸ é¦–æ¬¡åŠ è½½ä¼šä¸‹è½½ ~2.5GB æƒé‡ï¼Œè¯·è€å¿ƒç­‰å¾…...\\n\")\n",
        "\n",
        "# åŠ è½½ GPTQ é‡åŒ–æ¨¡å‹ï¼ˆAutoRound æ ¼å¼ï¼‰\n",
        "model = AutoModelForImageTextToText.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    mem_gb = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "    print(f\"âœ… AutoRound 4-bit model loaded\")\n",
        "    print(f\"GPU memory: {mem_gb:.2f} GB (é¢„æœŸ ~4GB)\")\n",
        "    torch.cuda.reset_peak_memory_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 6: ç”ŸæˆæŠ¥å‘Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "PROMPT_TEMPLATE = (\n",
        "    \"You are an expert radiologist. Describe this {view} view chest X-ray. \"\n",
        "    \"Provide a concise report consisting of Findings and Impression. \"\n",
        "    \"Focus on the heart, lungs, mediastinum, pleural space, and bones. \"\n",
        "    \"Do NOT use bullet points, asterisks, or section headers. \"\n",
        "    \"Do NOT include disclaimers or 'AI' warnings. Output pure medical text only.\"\n",
        ")\n",
        "\n",
        "def fix_image_path(path):\n",
        "    \"\"\"ä¿®æ­£ CSV ä¸­çš„å›¾ç‰‡è·¯å¾„ä¸ºå®é™… Kaggle datasets è·¯å¾„\"\"\"\n",
        "    if pd.isna(path) or not path:\n",
        "        return None\n",
        "    path = str(path).strip()\n",
        "    \n",
        "    if path.startswith(\"/kaggle/input/datasets/\"):\n",
        "        return path if os.path.exists(path) else None\n",
        "    \n",
        "    if path.startswith(\"/kaggle/input/mimic-cxr-dataset/\"):\n",
        "        new_path = path.replace(\"/kaggle/input/mimic-cxr-dataset/\", \"/kaggle/input/datasets/simhadrisadaram/mimic-cxr-dataset/\")\n",
        "        return new_path if os.path.exists(new_path) else None\n",
        "    \n",
        "    if not path.startswith(\"/\"):\n",
        "        full = os.path.join(DATASET_ROOT, path)\n",
        "        return full if os.path.exists(full) else None\n",
        "    \n",
        "    return path if os.path.exists(path) else None\n",
        "\n",
        "def get_single_image_path(cell_val):\n",
        "    if pd.isna(cell_val):\n",
        "        return None\n",
        "    s = str(cell_val).strip().replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\").split(\",\")[0].strip()\n",
        "    if \"files\" in s:\n",
        "        rel = \"files\" + s.split(\"files\", 1)[1]\n",
        "    else:\n",
        "        rel = s.strip(\"/\")\n",
        "    full = os.path.join(DATASET_ROOT, rel) if not rel.startswith(\"/\") else rel\n",
        "    return fix_image_path(full)\n",
        "\n",
        "def generate_report(model, processor, img_path, view=\"PA\"):\n",
        "    if not os.path.exists(img_path):\n",
        "        return \"\"\n",
        "    try:\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "    except:\n",
        "        return \"\"\n",
        "    prompt = PROMPT_TEMPLATE.format(view=view)\n",
        "    msgs = [{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": img}, {\"type\": \"text\", \"text\": prompt}]}]\n",
        "    inp = processor.apply_chat_template(msgs, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\").to(model.device, dtype=DTYPE)\n",
        "    L = inp[\"input_ids\"].shape[-1]\n",
        "    with torch.inference_mode():\n",
        "        out = model.generate(\n",
        "            **inp,\n",
        "            max_length=None,  # ç¦ç”¨é»˜è®¤ max_length\n",
        "            max_new_tokens=300,  # ä½¿ç”¨ç›¸å¯¹é•¿åº¦\n",
        "            min_new_tokens=5,  # å¼ºåˆ¶æœ€å°‘ç”Ÿæˆ\n",
        "            pad_token_id=0,  # æ˜¾å¼è®¾ç½® pad token\n",
        "            do_sample=False\n",
        "        )\n",
        "    txt = processor.decode(out[0][L:], skip_special_tokens=True)\n",
        "    return re.sub(r'\\s+', ' ', txt.replace(\"Findings:\", \"\").replace(\"Impression:\", \"\")).strip()\n",
        "\n",
        "# ç”ŸæˆæŠ¥å‘Š\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "GT_COL = \"Ground_Truth\" if \"Ground_Truth\" in df.columns else \"text\"\n",
        "IMG_COL = \"Image_Path\" if \"Image_Path\" in df.columns else None\n",
        "\n",
        "rows_out = []\n",
        "NUM = min(50, len(df))\n",
        "\n",
        "for idx, row in tqdm(df.head(NUM).iterrows(), total=NUM, desc=\"Generating AutoRound 4-bit reports\"):\n",
        "    path, view = None, \"PA\"\n",
        "    if IMG_COL:\n",
        "        path = fix_image_path(row.get(IMG_COL))\n",
        "        view = row.get(\"View\", \"PA\")\n",
        "    else:\n",
        "        for c, v in [(\"PA\", \"PA\"), (\"AP\", \"AP\"), (\"Lateral\", \"Lateral\")]:\n",
        "            if c in df.columns and (p := get_single_image_path(row.get(c))):\n",
        "                path, view = p, v\n",
        "                break\n",
        "    if not path:\n",
        "        continue\n",
        "    gt = str(row.get(GT_COL) or \"\").strip()\n",
        "    if not gt or gt.startswith(\"You are\"):\n",
        "        continue\n",
        "    rep = generate_report(model, processor, path, view)\n",
        "    rows_out.append({\n",
        "        \"subject_id\": row[\"subject_id\"],\n",
        "        \"View\": view,\n",
        "        \"Image_Path\": path,\n",
        "        \"Ground_Truth\": gt,\n",
        "        \"Generated_Report\": rep\n",
        "    })\n",
        "\n",
        "df_sub = pd.DataFrame(rows_out)\n",
        "print(f\"\\nâœ… Generated {len(df_sub)} reports\")\n",
        "\n",
        "# å¿«é€Ÿæ£€æŸ¥ç”Ÿæˆè´¨é‡\n",
        "print(\"\\n=== ç”ŸæˆæŠ¥å‘Šæ£€æŸ¥ ===\")\n",
        "print(f\"æ€»å…±ç”Ÿæˆ: {len(df_sub)} æ¡æŠ¥å‘Š\")\n",
        "print(f\"å‰ 3 æ¡æ•°æ®ï¼š\")\n",
        "for i in range(min(3, len(df_sub))):\n",
        "    print(f\"\\n[{i}] Ground Truth: {df_sub.iloc[i]['Ground_Truth'][:80]}...\")\n",
        "    print(f\"    Generated: {df_sub.iloc[i]['Generated_Report'][:80]}...\")\n",
        "\n",
        "empty_count = (df_sub['Generated_Report'].str.strip() == \"\").sum()\n",
        "print(f\"\\nç©ºæŠ¥å‘Šæ•°é‡: {empty_count} / {len(df_sub)}\")\n",
        "if empty_count > len(df_sub) * 0.5:\n",
        "    print(\"âŒ è­¦å‘Šï¼šè¶…è¿‡ä¸€åŠçš„æŠ¥å‘Šä¸ºç©ºï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 7a: RadGraph å…¼å®¹æ€§ä¿®å¤ï¼ˆå¿…é¡»å…ˆè¿è¡Œï¼ï¼‰\n",
        "\n",
        "**è¯´æ˜**ï¼šä¿®å¤ `transformers` 5.x ä¸ `radgraph` çš„å…¼å®¹æ€§é—®é¢˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "fixed_methods = []\n",
        "\n",
        "# 1. æ·»åŠ  encode_plus æ–¹æ³•\n",
        "if not hasattr(BertTokenizer, 'encode_plus'):\n",
        "    def encode_plus_wrapper(self, text, *args, **kwargs):\n",
        "        return self(text, *args, **kwargs)\n",
        "    BertTokenizer.encode_plus = encode_plus_wrapper\n",
        "    fixed_methods.append('encode_plus')\n",
        "\n",
        "# 2. æ·»åŠ  build_inputs_with_special_tokens æ–¹æ³•\n",
        "if not hasattr(BertTokenizer, 'build_inputs_with_special_tokens'):\n",
        "    def build_inputs_with_special_tokens_wrapper(self, token_ids_0, token_ids_1=None):\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        return [self.cls_token_id] + token_ids_0 + [self.sep_token_id] + token_ids_1 + [self.sep_token_id]\n",
        "    BertTokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens_wrapper\n",
        "    fixed_methods.append('build_inputs_with_special_tokens')\n",
        "\n",
        "# 3. æ·»åŠ  get_special_tokens_mask æ–¹æ³•\n",
        "if not hasattr(BertTokenizer, 'get_special_tokens_mask'):\n",
        "    def get_special_tokens_mask_wrapper(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        if already_has_special_tokens:\n",
        "            return super(BertTokenizer, self).get_special_tokens_mask(\n",
        "                token_ids_0=token_ids_0, token_ids_1=token_ids_1, already_has_special_tokens=True\n",
        "            )\n",
        "        if token_ids_1 is None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "    BertTokenizer.get_special_tokens_mask = get_special_tokens_mask_wrapper\n",
        "    fixed_methods.append('get_special_tokens_mask')\n",
        "\n",
        "if fixed_methods:\n",
        "    print(f\"âœ… RadGraph å…¼å®¹æ€§ä¿®å¤å·²åº”ç”¨: {', '.join(fixed_methods)}\")\n",
        "else:\n",
        "    print(\"âœ… BertTokenizer å·²æœ‰æ‰€æœ‰å¿…éœ€æ–¹æ³•\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 7b: RadGraph F1 è¯„ä¼°\n",
        "\n",
        "**æŒ‡æ ‡è¯´æ˜**ï¼ˆç™¾åˆ†åˆ¶ï¼‰ï¼š\n",
        "- **RG_E**: Entity F1ï¼ˆå®ä½“åŒ¹é…ï¼‰\n",
        "- **RG_ER**: Entity + Relation F1ï¼ˆå®ä½“+å…³ç³»ï¼Œ**è®ºæ–‡å¸¸ç”¨æŒ‡æ ‡**ï¼‰\n",
        "- **RG_ER_bar**: Complete Match F1ï¼ˆå®Œå…¨åŒ¹é…ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from radgraph import F1RadGraph\n",
        "import torch\n",
        "\n",
        "print(\"ğŸ” å¼€å§‹ RadGraph F1 è¯„ä¼°...\")\n",
        "print(f\"è¯„ä¼°æ ·æœ¬æ•°: {len(df_sub)}\\n\")\n",
        "\n",
        "# å‡†å¤‡æ•°æ®\n",
        "refs = df_sub[\"Ground_Truth\"].fillna(\"\").tolist()\n",
        "hyps = df_sub[\"Generated_Report\"].fillna(\"\").tolist()\n",
        "\n",
        "# è¿‡æ»¤æ‰ç©ºæŠ¥å‘Š\n",
        "valid_pairs = [(h, r) for h, r in zip(hyps, refs) if h and r and len(h.strip()) > 0]\n",
        "if len(valid_pairs) < len(hyps):\n",
        "    print(f\"âš ï¸ è·³è¿‡ {len(hyps) - len(valid_pairs)} æ¡ç©ºæŠ¥å‘Š\\n\")\n",
        "hyps_clean, refs_clean = zip(*valid_pairs) if valid_pairs else ([], [])\n",
        "\n",
        "# åˆå§‹åŒ– RadGraph\n",
        "print(\"Using device:\", \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "f1radgraph = F1RadGraph(reward_level=\"all\")\n",
        "\n",
        "# è®¡ç®— F1\n",
        "results = f1radgraph(hyps=list(hyps_clean), refs=list(refs_clean))\n",
        "\n",
        "# è§£æè¿”å›å€¼ï¼šresults[0] = (simple, partial, complete)\n",
        "avg_scores = results[0]\n",
        "simple_f1 = float(avg_scores[0])    # RG_ER_bar\n",
        "partial_f1 = float(avg_scores[1])   # RG_ER (è®ºæ–‡å¸¸ç”¨)\n",
        "complete_f1 = float(avg_scores[2])  # RG_E\n",
        "\n",
        "# æ˜¾ç¤ºç»“æœï¼ˆç™¾åˆ†åˆ¶ï¼‰\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"AutoRound 4-bit RadGraph F1 è¯„ä¼°ç»“æœï¼ˆç™¾åˆ†åˆ¶ï¼‰\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"RG_E (Entity):              {complete_f1*100:.2f}\")\n",
        "print(f\"RG_ER (Entity+Relation):    {partial_f1*100:.2f}  â† è®ºæ–‡å¸¸ç”¨\")\n",
        "print(f\"RG_ER_bar (Complete Match): {simple_f1*100:.2f}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    peak_mem = torch.cuda.max_memory_allocated(0) / 1e9\n",
        "    print(f\"\\nPeak GPU æ˜¾å­˜: {peak_mem:.2f} GB\")\n",
        "\n",
        "# ä¿å­˜ç»“æœ\n",
        "df_sub.to_csv(\"/kaggle/working/medgemma_autoround_4bit_reports.csv\", index=False)\n",
        "print(\"\\nâœ… ç»“æœå·²ä¿å­˜è‡³ /kaggle/working/medgemma_autoround_4bit_reports.csv\")\n",
        "print(\"\\nâœ… è¯„ä¼°å®Œæˆï¼\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
