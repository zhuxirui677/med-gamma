{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MedGemma 1.5 W4A8 é‡åŒ– + RadGraph F1 è¯„ä¼°\n",
        "\n",
        "## é‡åŒ–è¯´æ˜\n",
        "- **W4A8**ï¼š4-bit æƒé‡ + 8-bit æ¿€æ´»\n",
        "- **é¢„æœŸ**ï¼šF1 æ¥è¿‘åŸå§‹ï¼Œæ˜¾å­˜é€‚ä¸­é™ä½\n",
        "- **å‰ç½®**ï¼šéœ€å…ˆè¿è¡Œ 01_original è·å–åŸºçº¿\n",
        "\n",
        "## ç¯å¢ƒè¯´æ˜\n",
        "- **Kaggle P100**ï¼šPyTorch cu118\n",
        "- **transformers 4.47.1 + bitsandbytes**\n",
        "- **è¿è¡Œæµç¨‹**ï¼šå®‰è£… â†’ Restart Session â†’ Run All"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 1: å®‰è£…ï¼ˆå¿…é¡»å…ˆè¿è¡Œï¼Œå®Œæˆå Restart Sessionï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# W4A8 é‡åŒ–ç¯å¢ƒ\n",
        "import subprocess, sys, os, shutil\n",
        "\n",
        "TF_ENV = \"/kaggle/working/tf_env\"\n",
        "CONSTRAINTS = \"/kaggle/working/constraints.txt\"\n",
        "\n",
        "if os.path.exists(TF_ENV):\n",
        "    shutil.rmtree(TF_ENV)\n",
        "\n",
        "print(\"ä½¿ç”¨ Kaggle é¢„è£…çš„ PyTorch...\")\n",
        "\n",
        "subprocess.run([\"pip\", \"install\", \"-q\", \"bitsandbytes\"], check=True)\n",
        "\n",
        "with open(CONSTRAINTS, \"w\") as f:\n",
        "    f.write(\"transformers==4.47.1\\n\")\n",
        "\n",
        "subprocess.run([\n",
        "    \"pip\", \"install\", \"--target\", TF_ENV, \"-q\", \"-c\", CONSTRAINTS,\n",
        "    \"transformers==4.47.1\", \"pillow<12\", \"jinja2\",\n",
        "    \"-i\", \"https://pypi.tuna.tsinghua.edu.cn/simple\"\n",
        "], check=True)\n",
        "\n",
        "subprocess.run([\n",
        "    \"pip\", \"install\", \"-q\", \"radgraph\",\n",
        "    \"-i\", \"https://pypi.tuna.tsinghua.edu.cn/simple\"\n",
        "], check=True)\n",
        "\n",
        "sys.path.insert(0, TF_ENV)\n",
        "\n",
        "print(\"âœ… å®‰è£…å®Œæˆï¼Œè¯· Restart Session â†’ Run All\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 2: HuggingFace ç™»å½•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "from huggingface_hub import login\n",
        "\n",
        "try:\n",
        "    tok = UserSecretsClient().get_secret(\"zhuxirui11\")\n",
        "    if tok:\n",
        "        login(token=tok)\n",
        "        print(\"âœ… HF ç™»å½•æˆåŠŸ\")\n",
        "    else:\n",
        "        print(\"âš ï¸ HUGGINGFACE_TOKEN ä¸ºç©º\")\n",
        "except Exception as e:\n",
        "    print(\"âŒ æœªé…ç½® zhuxirui11 Secret\")\n",
        "    print(\"\\nè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®ï¼š\")\n",
        "    print(\"1. ç‚¹å‡»å³ä¾§ 'Add-ons' â†’ 'Secrets'\")\n",
        "    print(\"2. Label å¡«å†™ï¼šzhuxirui11\")\n",
        "    print(\"3. Value å¡«å†™ä½ çš„ HF token\")\n",
        "    print(\"4. ä¿å­˜åé‡æ–°è¿è¡Œæœ¬ Cell\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 3: ç¯å¢ƒæ£€æŸ¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, torch\n",
        "\n",
        "print(f\"Python: {sys.version}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    # W4A8 æ¿€æ´»ç”¨ FP16\n",
        "    DTYPE = torch.float16\n",
        "    print(\"Precision: FP16 (W4A8 é‡åŒ–)\")\n",
        "else:\n",
        "    DTYPE = torch.float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 4: å¯¼å…¥ä¸è·¯å¾„é…ç½®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os, gc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "TF_ENV = \"/kaggle/working/tf_env\"\n",
        "if TF_ENV not in sys.path:\n",
        "    sys.path.insert(0, TF_ENV)\n",
        "elif sys.path[0] != TF_ENV:\n",
        "    sys.path.remove(TF_ENV)\n",
        "    sys.path.insert(0, TF_ENV)\n",
        "\n",
        "DATASET_ROOT = \"/kaggle/input/datasets/simhadrisadaram/mimic-cxr-dataset/official_data_iccv_final\"\n",
        "CSV_CANDIDATES = [\n",
        "    \"/kaggle/input/datasets/xiruizhu1111/clean-data/mimic_eval_single_image_final_233.csv\",\n",
        "    \"/kaggle/input/datasets/xiruizhu1111/clean-train-data/mimic_eval_single_image_final_233.csv\",\n",
        "    \"/kaggle/input/clean-data/mimic_eval_single_image_final_233.csv\",\n",
        "    \"/kaggle/working/mimic_eval_single_image_final_233.csv\",\n",
        "]\n",
        "\n",
        "CSV_PATH = None\n",
        "for p in CSV_CANDIDATES:\n",
        "    if os.path.exists(p):\n",
        "        CSV_PATH = p\n",
        "        break\n",
        "\n",
        "if not CSV_PATH:\n",
        "    print(\"âŒ æœªæ‰¾åˆ° CSV æ–‡ä»¶ï¼å°è¯•çš„è·¯å¾„ï¼š\")\n",
        "    for p in CSV_CANDIDATES:\n",
        "        print(f\"  - {p}\")\n",
        "    raise FileNotFoundError(\"CSV æ–‡ä»¶ä¸å­˜åœ¨\")\n",
        "\n",
        "# éªŒè¯ transformers ç‰ˆæœ¬\n",
        "import transformers\n",
        "tf_ver = transformers.__version__\n",
        "if tf_ver.startswith('5.'):\n",
        "    raise RuntimeError(\n",
        "        f\"âŒ transformers {tf_ver} ä¸å…¼å®¹ï¼éœ€è¦ 4.47.1\\n\"\n",
        "        f\"è§£å†³æ–¹æ³•ï¼šé‡æ–°è¿è¡Œ Cell 1ï¼Œç¡®ä¿çœ‹åˆ° 'transformers-4.47.1'ï¼Œç„¶å Restart Session\"\n",
        "    )\n",
        "print(f\"âœ… transformers: {tf_ver}\")\n",
        "\n",
        "print(f\"Dataset: {DATASET_ROOT}\")\n",
        "print(f\"âœ… CSV: {CSV_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 4.5: æ£€æŸ¥ CSV ç»“æ„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_check = pd.read_csv(CSV_PATH)\n",
        "print(f\"âœ… CSV: {len(df_check)} è¡Œ\")\n",
        "print(f\"åˆ—å: {list(df_check.columns)}\")\n",
        "print(df_check.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 5: åŠ è½½ MedGemma W4A8 é‡åŒ–æ¨¡å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in list(sys.modules.keys()):\n",
        "    if k == \"transformers\" or k.startswith(\"transformers.\"):\n",
        "        del sys.modules[k]\n",
        "\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"google/medgemma-1.5-4b-it\"\n",
        "print(f\"Loading MedGemma W4A8 (4-bit weight + 8-bit activation)...\")\n",
        "\n",
        "# W4A8 é‡åŒ–é…ç½®\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,  # W4A8 ç”¨åŒé‡é‡åŒ–æå‡ç²¾åº¦\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "model = AutoModelForImageTextToText.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    mem_gb = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "    print(f\"âœ… W4A8 model loaded, GPU memory: {mem_gb:.2f} GB\")\n",
        "    torch.cuda.reset_peak_memory_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 6: ç”ŸæˆæŠ¥å‘Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "PROMPT_TEMPLATE = \"Generate a radiology report for this {view} chest X-ray.\"\n",
        "\n",
        "def fix_image_path(path):\n",
        "    if pd.isna(path) or not path:\n",
        "        return None\n",
        "    path = str(path).strip()\n",
        "    if path.startswith(\"/kaggle/input/datasets/\"):\n",
        "        return path if os.path.exists(path) else None\n",
        "    if path.startswith(\"/kaggle/input/mimic-cxr-dataset/\"):\n",
        "        new_path = path.replace(\"/kaggle/input/mimic-cxr-dataset/\", \"/kaggle/input/datasets/simhadrisadaram/mimic-cxr-dataset/\")\n",
        "        return new_path if os.path.exists(new_path) else None\n",
        "    if not path.startswith(\"/\"):\n",
        "        full = os.path.join(DATASET_ROOT, path)\n",
        "        return full if os.path.exists(full) else None\n",
        "    return path if os.path.exists(path) else None\n",
        "\n",
        "def get_single_image_path(cell_val):\n",
        "    if pd.isna(cell_val):\n",
        "        return None\n",
        "    s = str(cell_val).strip().replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\").split(\",\")[0].strip()\n",
        "    if \"files\" in s:\n",
        "        rel = \"files\" + s.split(\"files\", 1)[1]\n",
        "    else:\n",
        "        rel = s.strip(\"/\")\n",
        "    full = os.path.join(DATASET_ROOT, rel) if not rel.startswith(\"/\") else rel\n",
        "    return fix_image_path(full)\n",
        "\n",
        "def generate_report(model, processor, img_path, view=\"PA\"):\n",
        "    if not os.path.exists(img_path):\n",
        "        return \"\"\n",
        "    try:\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "    except:\n",
        "        return \"\"\n",
        "    prompt = PROMPT_TEMPLATE.format(view=view)\n",
        "    msgs = [{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": img}, {\"type\": \"text\", \"text\": prompt}]}]\n",
        "    inp = processor.apply_chat_template(msgs, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\").to(model.device, dtype=DTYPE)\n",
        "    L = inp[\"input_ids\"].shape[-1]\n",
        "    with torch.inference_mode():\n",
        "        out = model.generate(\n",
        "            **inp,\n",
        "            max_length=None,  # ç¦ç”¨é»˜è®¤ max_length\n",
        "            max_new_tokens=300,  # ä½¿ç”¨ç›¸å¯¹é•¿åº¦\n",
        "            min_new_tokens=5,  # å¼ºåˆ¶æœ€å°‘ç”Ÿæˆ\n",
        "            pad_token_id=0,  # æ˜¾å¼è®¾ç½® pad token\n",
        "            do_sample=False\n",
        "        )\n",
        "    txt = processor.decode(out[0][L:], skip_special_tokens=True)\n",
        "    return re.sub(r'\\s+', ' ', txt.replace(\"Findings:\", \"\").replace(\"Impression:\", \"\")).strip()\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "GT_COL = \"Ground_Truth\" if \"Ground_Truth\" in df.columns else \"text\"\n",
        "IMG_COL = \"Image_Path\" if \"Image_Path\" in df.columns else None\n",
        "\n",
        "rows_out = []\n",
        "NUM = min(50, len(df))\n",
        "\n",
        "for idx, row in tqdm(df.head(NUM).iterrows(), total=NUM, desc=\"Generating W4A8 reports\"):\n",
        "    path, view = None, \"PA\"\n",
        "    if IMG_COL:\n",
        "        path = fix_image_path(row.get(IMG_COL))\n",
        "        view = row.get(\"View\", \"PA\")\n",
        "    else:\n",
        "        for c, v in [(\"PA\", \"PA\"), (\"AP\", \"AP\"), (\"Lateral\", \"Lateral\")]:\n",
        "            if c in df.columns and (p := get_single_image_path(row.get(c))):\n",
        "                path, view = p, v\n",
        "                break\n",
        "    if not path:\n",
        "        continue\n",
        "    gt = str(row.get(GT_COL) or \"\").strip()\n",
        "    if not gt or gt.startswith(\"You are\"):\n",
        "        continue\n",
        "    rep = generate_report(model, processor, path, view)\n",
        "    rows_out.append({\n",
        "        \"subject_id\": row[\"subject_id\"],\n",
        "        \"View\": view,\n",
        "        \"Image_Path\": path,\n",
        "        \"Ground_Truth\": gt,\n",
        "        \"Generated_Report\": rep\n",
        "    })\n",
        "\n",
        "df_sub = pd.DataFrame(rows_out)\n",
        "print(f\"\\nâœ… Generated {len(df_sub)} reports\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 7a: RadGraph å…¼å®¹æ€§ä¿®å¤ï¼ˆå¿…é¡»å…ˆè¿è¡Œï¼ï¼‰\n",
        "\n",
        "**è¯´æ˜**ï¼šä¿®å¤ `transformers` 5.x ä¸ `radgraph` çš„å…¼å®¹æ€§é—®é¢˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "fixed_methods = []\n",
        "\n",
        "# 1. æ·»åŠ  encode_plus æ–¹æ³•\n",
        "if not hasattr(BertTokenizer, 'encode_plus'):\n",
        "    def encode_plus_wrapper(self, text, *args, **kwargs):\n",
        "        return self(text, *args, **kwargs)\n",
        "    BertTokenizer.encode_plus = encode_plus_wrapper\n",
        "    fixed_methods.append('encode_plus')\n",
        "\n",
        "# 2. æ·»åŠ  build_inputs_with_special_tokens æ–¹æ³•\n",
        "if not hasattr(BertTokenizer, 'build_inputs_with_special_tokens'):\n",
        "    def build_inputs_with_special_tokens_wrapper(self, token_ids_0, token_ids_1=None):\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        return [self.cls_token_id] + token_ids_0 + [self.sep_token_id] + token_ids_1 + [self.sep_token_id]\n",
        "    BertTokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens_wrapper\n",
        "    fixed_methods.append('build_inputs_with_special_tokens')\n",
        "\n",
        "# 3. æ·»åŠ  get_special_tokens_mask æ–¹æ³•\n",
        "if not hasattr(BertTokenizer, 'get_special_tokens_mask'):\n",
        "    def get_special_tokens_mask_wrapper(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        if already_has_special_tokens:\n",
        "            return super(BertTokenizer, self).get_special_tokens_mask(\n",
        "                token_ids_0=token_ids_0, token_ids_1=token_ids_1, already_has_special_tokens=True\n",
        "            )\n",
        "        if token_ids_1 is None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "    BertTokenizer.get_special_tokens_mask = get_special_tokens_mask_wrapper\n",
        "    fixed_methods.append('get_special_tokens_mask')\n",
        "\n",
        "if fixed_methods:\n",
        "    print(f\"âœ… RadGraph å…¼å®¹æ€§ä¿®å¤å·²åº”ç”¨: {', '.join(fixed_methods)}\")\n",
        "else:\n",
        "    print(\"âœ… BertTokenizer å·²æœ‰æ‰€æœ‰å¿…éœ€æ–¹æ³•\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 7b: RadGraph F1 è¯„ä¼°\n",
        "\n",
        "**æŒ‡æ ‡è¯´æ˜**ï¼ˆç™¾åˆ†åˆ¶ï¼‰ï¼š\n",
        "- **RG_E**: Entity F1ï¼ˆå®ä½“åŒ¹é…ï¼‰\n",
        "- **RG_ER**: Entity + Relation F1ï¼ˆå®ä½“+å…³ç³»ï¼Œ**è®ºæ–‡å¸¸ç”¨æŒ‡æ ‡**ï¼‰\n",
        "- **RG_ER_bar**: Complete Match F1ï¼ˆå®Œå…¨åŒ¹é…ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from radgraph import F1RadGraph\n",
        "\n",
        "print(\"ğŸ” å¼€å§‹ RadGraph F1 è¯„ä¼°...\")\n",
        "print(f\"è¯„ä¼°æ ·æœ¬æ•°: {len(df_sub)}\\n\")\n",
        "\n",
        "# å‡†å¤‡æ•°æ®\n",
        "refs = df_sub[\"Ground_Truth\"].fillna(\"\").tolist()\n",
        "hyps = df_sub[\"Generated_Report\"].fillna(\"\").tolist()\n",
        "\n",
        "# è¿‡æ»¤æ‰ç©ºæŠ¥å‘Š\n",
        "valid_pairs = [(h, r) for h, r in zip(hyps, refs) if h and r and len(h.strip()) > 0]\n",
        "if len(valid_pairs) < len(hyps):\n",
        "    print(f\"âš ï¸ è·³è¿‡ {len(hyps) - len(valid_pairs)} æ¡ç©ºæŠ¥å‘Š\\n\")\n",
        "hyps_clean, refs_clean = zip(*valid_pairs) if valid_pairs else ([], [])\n",
        "\n",
        "# åˆå§‹åŒ– RadGraph\n",
        "f1radgraph = F1RadGraph(reward_level=\"all\")\n",
        "\n",
        "# è®¡ç®— F1\n",
        "results = f1radgraph(hyps=list(hyps_clean), refs=list(refs_clean))\n",
        "\n",
        "# è§£æè¿”å›å€¼ï¼šresults[0] = (simple, partial, complete)\n",
        "avg_scores = results[0]\n",
        "simple_f1 = float(avg_scores[0])    # RG_ER_bar\n",
        "partial_f1 = float(avg_scores[1])   # RG_ER (è®ºæ–‡å¸¸ç”¨)\n",
        "complete_f1 = float(avg_scores[2])  # RG_E\n",
        "\n",
        "# æ˜¾ç¤ºç»“æœï¼ˆç™¾åˆ†åˆ¶ï¼‰\n",
        "print(\"=\" * 60)\n",
        "print(\"MedGemma W4A8 RadGraph F1 è¯„ä¼°ç»“æœï¼ˆç™¾åˆ†åˆ¶ï¼‰\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"RG_E (Entity):              {complete_f1*100:.2f}\")\n",
        "print(f\"RG_ER (Entity+Relation):    {partial_f1*100:.2f}  â† è®ºæ–‡å¸¸ç”¨\")\n",
        "print(f\"RG_ER_bar (Complete Match): {simple_f1*100:.2f}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ä¿å­˜åˆ†æ•°ï¼ˆå°æ•°æ ¼å¼ï¼‰\n",
        "W4A8_SCORES = {\"rg_e\": complete_f1, \"rg_er\": partial_f1, \"rg_er_bar\": simple_f1}\n",
        "W4A8_GPU_GB = torch.cuda.max_memory_allocated(0) / (1024**3) if torch.cuda.is_available() else 0\n",
        "print(f\"\\nPeak GPU æ˜¾å­˜: {W4A8_GPU_GB:.2f} GB\")\n",
        "print(\"\\nâœ… è¯„ä¼°å®Œæˆï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 8: ä¿å­˜ç»“æœ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "del model, processor\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "df_sub.to_csv(\"/kaggle/working/w4a8_medgemma_results.csv\", index=False)\n",
        "with open(\"/kaggle/working/w4a8_scores.json\", \"w\") as f:\n",
        "    json.dump({\"scores\": W4A8_SCORES, \"gpu_gb\": W4A8_GPU_GB}, f)\n",
        "\n",
        "print(\"âœ… W4A8 ç»“æœå·²ä¿å­˜\")\n",
        "print(\"\\nä¸‹ä¸€æ­¥ï¼šè¿è¡Œ 04_compare å¯¹æ¯”ç»“æœ\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
