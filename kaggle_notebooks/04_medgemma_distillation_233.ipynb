{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 0: 环境设置（Kaggle P100）\n",
        "\n",
        "- **P100 兼容**：Kaggle 预装 PyTorch cu128 不支持 P100 (sm_60)，需先运行下方安装 Cell 安装 PyTorch cu118\n",
        "- **安装后**：若仍报 GPU 不兼容，请 **Restart Session** 后重新 Run All"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# P100 (sm_60) 需 PyTorch cu118。transformers 4.46 安装到独立目录，避免与系统 5.x 冲突\n",
        "import subprocess\n",
        "import sys\n",
        "subprocess.run([\"pip\", \"install\", \"-q\", \"torch==2.7.1\", \"torchvision==0.22.1\", \"torchaudio==2.7.1\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"], capture_output=True)\n",
        "subprocess.run([\"pip\", \"install\", \"-q\", \"pillow>=9.0,<12\", \"jinja2\"], capture_output=True)\n",
        "TF_ENV = \"/kaggle/working/transformers_4.46\"\n",
        "subprocess.run([\"pip\", \"install\", \"--target\", TF_ENV, \"--no-cache-dir\", \"-q\", \"transformers==4.46.0\", \"radgraph\"], capture_output=True)\n",
        "subprocess.run([\"pip\", \"install\", \"-q\", \"bitsandbytes\", \"peft\"], capture_output=True)\n",
        "sys.path.insert(0, TF_ENV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 1: 蒸馏说明\n",
        "\n",
        "## 逻辑\n",
        "- **Teacher**：原始 MedGemma，对 233 张图生成报告（或直接用 CSV 中 Generated_Report，因 233 由原模型筛选）\n",
        "- **Student**：QLoRA（4-bit 量化 + LoRA），学习模仿 teacher 输出\n",
        "- **蒸馏目标**：teacher 的生成序列作为 target，student 用 CE 损失逐 token 拟合"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 2: 环境检查（需先运行上方安装）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "print(f\"Python: {sys.version}\")\n",
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    DTYPE = torch.bfloat16 if torch.cuda.get_device_capability(0)[0] >= 8 else torch.float16\n",
        "else:\n",
        "    DTYPE = torch.float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 3: 路径与数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "CSV_CANDIDATES = [\"/kaggle/input/mimic-cxr-dataset/mimic_eval_single_image_final_233.csv\", \"/kaggle/input/mimic-cxr-dataset/official_data_iccv_final/mimic_eval_single_image_final_233.csv\", \"/kaggle/input/mimic-eval-233/mimic_eval_single_image_final_233.csv\", \"/kaggle/working/mimic_eval_single_image_final_233.csv\", \"./mimic_eval_single_image_final_233.csv\"]\n",
        "CSV_PATH = next((p for p in CSV_CANDIDATES if os.path.exists(p)), CSV_CANDIDATES[0])\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(f\"共 {len(df)} 条\")\n",
        "\n",
        "# 蒸馏目标：用 teacher 输出。若 CSV 中 Generated_Report 来自原模型，可直接用；否则需先跑 teacher 生成\n",
        "USE_CSV_TEACHER = df[\"Generated_Report\"].notna().all() and (df[\"Generated_Report\"].str.len() > 10).all()\n",
        "print(f\"使用 CSV 中 Generated_Report 作为 teacher 目标: {USE_CSV_TEACHER}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 4: 获取 Teacher 目标（若 CSV 无则用原模型生成）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if USE_CSV_TEACHER:\n",
        "    teacher_targets = df[\"Generated_Report\"].fillna(\"\").tolist()\n",
        "    print(\"使用 CSV 中已有 teacher 输出\")\n",
        "else:\n",
        "    from transformers import AutoProcessor, AutoModelForImageTextToText\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    model_id = \"google/medgemma-1.5-4b-it\"\n",
        "    print(\"加载 Teacher (原模型)...\")\n",
        "    teacher = AutoModelForImageTextToText.from_pretrained(model_id, torch_dtype=DTYPE, device_map=\"auto\")\n",
        "    proc = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "    def gen(img_path, prompt=\"Describe this chest X-ray in a radiology report format.\"):\n",
        "        if not os.path.exists(img_path):\n",
        "            return \"\"\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except Exception:\n",
        "            return \"\"\n",
        "        msgs = [{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": img}, {\"type\": \"text\", \"text\": prompt}]}]\n",
        "        inp = proc.apply_chat_template(msgs, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\").to(teacher.device, dtype=DTYPE)\n",
        "        L = inp[\"input_ids\"].shape[-1]\n",
        "        with torch.inference_mode():\n",
        "            out = teacher.generate(**inp, max_new_tokens=512, do_sample=False)\n",
        "        return proc.decode(out[0][L:], skip_special_tokens=True).strip()\n",
        "\n",
        "    teacher_targets = []\n",
        "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        teacher_targets.append(gen(row[\"Image_Path\"]))\n",
        "\n",
        "    del teacher\n",
        "    del proc\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    print(\"Teacher 已释放\")\n",
        "\n",
        "df[\"teacher_target\"] = teacher_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 5: 构建蒸馏数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DistillDataset(Dataset):\n",
        "    def __init__(self, df, processor, image_col=\"Image_Path\", target_col=\"teacher_target\", prompt=\"Describe this chest X-ray in a radiology report format.\"):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.processor = processor\n",
        "        self.image_col = image_col\n",
        "        self.target_col = target_col\n",
        "        self.prompt = prompt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        path = row[self.image_col]\n",
        "        target = str(row[self.target_col] or \"\")\n",
        "        img = Image.open(path).convert(\"RGB\") if os.path.exists(path) else Image.new(\"RGB\", (224, 224), 0)\n",
        "        msgs = [{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": img}, {\"type\": \"text\", \"text\": self.prompt}]}]\n",
        "        full = msgs + [{\"role\": \"assistant\", \"content\": target}]\n",
        "        text = self.processor.apply_chat_template(full, tokenize=False, add_generation_prompt=False)\n",
        "        return {\"text\": text, \"image\": img}\n",
        "\n",
        "from transformers import AutoProcessor\n",
        "proc = AutoProcessor.from_pretrained(\"google/medgemma-1.5-4b-it\")\n",
        "ds = DistillDataset(df, proc)\n",
        "print(f\"蒸馏样本数: {len(ds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 6: 加载 Student（QLoRA）并训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForImageTextToText, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    texts = [b[\"text\"] for b in batch]\n",
        "    images = [b[\"image\"] for b in batch]\n",
        "    msgs = [[{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": im}, {\"type\": \"text\", \"text\": \"Describe this chest X-ray.\"}]}] for im in images]\n",
        "    out = proc(\n",
        "        text=[proc.apply_chat_template(m, tokenize=False, add_generation_prompt=True) for m in msgs],\n",
        "        images=images,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "    )\n",
        "    return out\n",
        "\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "model_id = \"google/medgemma-1.5-4b-it\"\n",
        "print(\"加载 Student (QLoRA)...\")\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "bnb = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=DTYPE, bnb_4bit_quant_type=\"nf4\")\n",
        "\n",
        "model = AutoModelForImageTextToText.from_pretrained(model_id, quantization_config=bnb, device_map=\"auto\")\n",
        "\n",
        "lora = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        ")\n",
        "model = get_peft_model(model, lora)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 7: 训练循环（蒸馏 CE 损失）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# 简化：用 SFT 方式，target 为 teacher 序列\n",
        "train_args = TrainingArguments(\n",
        "    output_dir=\"/kaggle/working/medgemma_distill_lora\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-5,\n",
        "    fp16=not (DTYPE == torch.bfloat16),\n",
        "    bf16=(DTYPE == torch.bfloat16),\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "# 需自定义 DataCollator 处理 image+text；若 proc 不支持 batch image，可逐条训练\n",
        "# 此处用简化版：仅对有效样本训练\n",
        "train_df = df[df[\"teacher_target\"].str.len() > 20].head(100)\n",
        "train_ds = DistillDataset(train_df, proc)\n",
        "\n",
        "def data_collator(batch):\n",
        "    # 简化 collator：返回可用的 batch\n",
        "    return batch\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=train_args,\n",
        "    train_dataset=train_ds,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# 注意：MedGemma 的 Trainer 需自定义 compute_loss 以处理 image+text，此处为框架示例\n",
        "# 完整实现需继承 Trainer 并重写 compute_loss，或使用 trl SFTTrainer\n",
        "print(\"训练框架已就绪；完整 image+text 蒸馏建议用 trl SFTTrainer 或自定义 Trainer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 8: 手动蒸馏训练循环（兼容 image+text）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "model.train()\n",
        "opt = AdamW(model.parameters(), lr=2e-5)\n",
        "BATCH = 2\n",
        "EPOCHS = 2\n",
        "\n",
        "for ep in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for i in range(0, min(50, len(train_ds)), BATCH):\n",
        "        batch = [train_ds[j] for j in range(i, min(i + BATCH, len(train_ds)))]\n",
        "        inputs_list = []\n",
        "        for b in batch:\n",
        "            msgs = [{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": b[\"image\"]}, {\"type\": \"text\", \"text\": \"Describe this chest X-ray in a radiology report format.\"}]}]\n",
        "            inp = proc.apply_chat_template(msgs, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\")\n",
        "            target_text = b[\"text\"].split(\"model\\n\")[-1] if \"model\\n\" in b[\"text\"] else b[\"text\"]\n",
        "            target_ids = proc(text=target_text, return_tensors=\"pt\", truncation=True, max_length=512)[\"input_ids\"]\n",
        "            full_ids = torch.cat([inp[\"input_ids\"], target_ids], dim=1)\n",
        "            if \"pixel_values\" in inp:\n",
        "                full_ids = full_ids.to(model.device)\n",
        "                pixel = inp[\"pixel_values\"].to(model.device, dtype=DTYPE)\n",
        "                out = model(input_ids=full_ids[:, :-1], pixel_values=pixel, labels=full_ids[:, 1:].clone())\n",
        "            else:\n",
        "                out = model(input_ids=full_ids[:, :-1].to(model.device), labels=full_ids[:, 1:].clone().to(model.device))\n",
        "            loss = out.loss if hasattr(out, \"loss\") else out[0]\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "            total_loss += loss.item()\n",
        "        if (i // BATCH) % 5 == 0:\n",
        "            print(f\"Epoch {ep+1} batch {i//BATCH} loss {total_loss/(i//BATCH+1):.4f}\")\n",
        "    print(f\"Epoch {ep+1} avg loss: {total_loss / (len(range(0, min(50, len(train_ds)), BATCH)):.4f}\")\n",
        "\n",
        "model.save_pretrained(\"/kaggle/working/medgemma_distill_lora\")\n",
        "proc.save_pretrained(\"/kaggle/working/medgemma_distill_lora\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
