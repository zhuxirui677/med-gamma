{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MedGemma 1.5 量化结果对比\n",
        "\n",
        "## 对比项目\n",
        "- **Original (W4A16/FP16)**：全精度基线\n",
        "- **W4A4**：4-bit 权重 + 4-bit 激活\n",
        "- **W4A8**：4-bit 权重 + 8-bit 激活\n",
        "\n",
        "## 前置条件\n",
        "需先运行 01/02/03 Notebooks 生成各自的 scores.json\n",
        "\n",
        "## 评估指标\n",
        "- **RadGraph F1**：RG_E（实体）、RG_ER（实体+关系）、RG_ER_bar（完整）\n",
        "- **GPU 显存**：峰值占用（GB）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 1: 加载结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def load_scores(filename):\n",
        "    path = f\"/kaggle/working/{filename}\"\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"⚠️ 未找到 {filename}，请先运行对应 Notebook\")\n",
        "        return None\n",
        "    with open(path) as f:\n",
        "        return json.load(f)\n",
        "\n",
        "original = load_scores(\"original_scores.json\")\n",
        "w4a4 = load_scores(\"w4a4_scores.json\")\n",
        "w4a8 = load_scores(\"w4a8_scores.json\")\n",
        "\n",
        "print(\"✅ 结果加载完成\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 2: RadGraph F1 对比"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 构建对比表\n",
        "data = []\n",
        "\n",
        "if original:\n",
        "    s = original[\"scores\"]\n",
        "    data.append([\"Original (FP16)\", f\"{s['rg_e']*100:.2f}\", f\"{s['rg_er']*100:.2f}\", f\"{s['rg_er_bar']*100:.2f}\", f\"{original['gpu_gb']:.2f}\"])\n",
        "\n",
        "if w4a4:\n",
        "    s = w4a4[\"scores\"]\n",
        "    delta = ((s['rg_er'] - original['scores']['rg_er']) / original['scores']['rg_er'] * 100) if original else 0\n",
        "    mem_delta = ((w4a4['gpu_gb'] - original['gpu_gb']) / original['gpu_gb'] * 100) if original else 0\n",
        "    data.append([\"W4A4\", f\"{s['rg_e']*100:.2f}\", f\"{s['rg_er']*100:.2f} ({delta:+.1f}%)\", f\"{s['rg_er_bar']*100:.2f}\", f\"{w4a4['gpu_gb']:.2f} ({mem_delta:+.1f}%)\"])\n",
        "\n",
        "if w4a8:\n",
        "    s = w4a8[\"scores\"]\n",
        "    delta = ((s['rg_er'] - original['scores']['rg_er']) / original['scores']['rg_er'] * 100) if original else 0\n",
        "    mem_delta = ((w4a8['gpu_gb'] - original['gpu_gb']) / original['gpu_gb'] * 100) if original else 0\n",
        "    data.append([\"W4A8\", f\"{s['rg_e']*100:.2f}\", f\"{s['rg_er']*100:.2f} ({delta:+.1f}%)\", f\"{s['rg_er_bar']*100:.2f}\", f\"{w4a8['gpu_gb']:.2f} ({mem_delta:+.1f}%)\"])\n",
        "\n",
        "df_compare = pd.DataFrame(data, columns=[\"Model\", \"RG_E\", \"RG_ER (论文常用)\", \"RG_ER_bar\", \"GPU Memory (GB)\"])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MedGemma 1.5 量化对比（Kaggle P100）\")\n",
        "print(\"=\" * 80)\n",
        "print(df_compare.to_string(index=False))\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 保存对比表\n",
        "df_compare.to_csv(\"/kaggle/working/comparison_results.csv\", index=False)\n",
        "print(\"\\n✅ 对比结果已保存至 /kaggle/working/comparison_results.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 3: 可视化对比"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if original and w4a4 and w4a8:\n",
        "    models = [\"Original\", \"W4A4\", \"W4A8\"]\n",
        "    rg_er_scores = [\n",
        "        original[\"scores\"][\"rg_er\"] * 100,\n",
        "        w4a4[\"scores\"][\"rg_er\"] * 100,\n",
        "        w4a8[\"scores\"][\"rg_er\"] * 100\n",
        "    ]\n",
        "    gpu_mem = [\n",
        "        original[\"gpu_gb\"],\n",
        "        w4a4[\"gpu_gb\"],\n",
        "        w4a8[\"gpu_gb\"]\n",
        "    ]\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # RadGraph F1\n",
        "    ax1.bar(models, rg_er_scores, color=[\"#4CAF50\", \"#FF9800\", \"#2196F3\"])\n",
        "    ax1.set_ylabel(\"RG_ER Score\")\n",
        "    ax1.set_title(\"RadGraph F1 (Entity+Relation)\")\n",
        "    ax1.set_ylim(0, max(rg_er_scores) * 1.2)\n",
        "    for i, v in enumerate(rg_er_scores):\n",
        "        ax1.text(i, v + 1, f\"{v:.2f}\", ha=\"center\", fontsize=10)\n",
        "\n",
        "    # GPU Memory\n",
        "    ax2.bar(models, gpu_mem, color=[\"#4CAF50\", \"#FF9800\", \"#2196F3\"])\n",
        "    ax2.set_ylabel(\"GPU Memory (GB)\")\n",
        "    ax2.set_title(\"Peak GPU Memory Usage\")\n",
        "    ax2.set_ylim(0, max(gpu_mem) * 1.2)\n",
        "    for i, v in enumerate(gpu_mem):\n",
        "        ax2.text(i, v + 0.2, f\"{v:.2f}\", ha=\"center\", fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/kaggle/working/comparison_plot.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(\"✅ 可视化已保存至 /kaggle/working/comparison_plot.png\")\n",
        "else:\n",
        "    print(\"⚠️ 缺少部分结果，请先运行 01/02/03 Notebooks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 总结\n",
        "\n",
        "## 预期结果\n",
        "- **Original**：RG_ER ≈ 27–30（MIMIC-CXR 论文基线），GPU ≈ 8–10 GB\n",
        "- **W4A4**：RG_ER 略降 2–5%，GPU 显著降低至 3–5 GB\n",
        "- **W4A8**：RG_ER 接近原始（<2% 降幅），GPU 适中降低至 5–7 GB\n",
        "\n",
        "## 关键发现\n",
        "- W4A8 在 P100 上可作为最佳平衡点（精度损失小，显存节省明显）\n",
        "- W4A4 适合极端显存受限场景（如边缘设备）"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
